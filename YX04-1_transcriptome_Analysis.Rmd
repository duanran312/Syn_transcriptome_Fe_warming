---
title: "YX04-1_DE_Analysis"
author: "ran"
date: "Jan 7, 2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

## change workdir

```{r, include=FALSE}
workdir="/Users/randuan/Documents/USC/synecho/transcriptomes/10_DE_analysis_YX04-1"
setwd(workdir)
cat("\n==>", as.character(Sys.time()), "setting working directory to ", workdir, "\n")
```

## Load required libraries

```{r, message=FALSE, warning=FALSE, echo=FALSE}
cat("\n==>", as.character(Sys.time()), "loading required packages ...\n")
# Install R and required Bioconductor packages if neccesary:
try(library(BiocManager), install.packages("BiocManager"))
library(BiocManager)
#BiocManager::install(c('edgeR', 'DESeq2', 'NOISeq', 'dendextend', 'phyloseq', 'apeglm', 'pheatmap'))
install.packages("FactoMineR")
library("FactoMineR")
library("edgeR")
library("NOISeq")
library("DESeq2")
library("dendextend")
library('phyloseq')
library('ggplot2')
library("apeglm")
library("pheatmap")
```

## Load functions

```{r, message=FALSE, warning=FALSE, echo=FALSE}
############################
#  Functions 
############################

#-----------------------------------------------
# read in gff file, return a data.frame object
#-----------------------------------------------
gffReader <- function(gffFile, nrows = -1) {
  
  # print processing info
  cat("\n==>", as.character(Sys.time()), "reading gff file ", gffFile, "\n")

  # read in gffFile as dataframe using read.table
  gff = read.table(gffFile, sep="\t", as.is=TRUE, quote="",
                   header=FALSE, comment.char="#", nrows = nrows,
                   colClasses=c("character", "character", "character", 
                                "integer", "integer", "character", "character", 
                                "character", "character")
  )
  
  cat("\n==>", as.character(Sys.time()), "class of gff is ", class(gff), "\n")
  
  # assign column names
  colnames(gff) = c("seqname", "source", "feature", "start", "end", 
                    "score", "strand", "frame", "attributes"
  )
  
  # print how many records totally get from this gff file
  cat("\n==>", as.character(Sys.time()), " found", nrow(gff), "rows with classes:", paste(sapply(gff, class), collapse=", "), "\n")

  # if start and end is NA, stop, stopifnot like assert in Python, all should be True
  stopifnot(!any(is.na(gff$start)), !any(is.na(gff$end)))
  
  cat("\n==>", as.character(Sys.time()),  " found", nrow(gff), "rows after filtration!\n")
  
  return(gff)
}


#----------------------------------------------------
# get attribute item from attributes using identifier
#----------------------------------------------------

getAttributeField <- function (x, field, attrsep = ";") {
  
  # split attributes str based on ";", fixed = TRUE doesnot allow regex, split exactly
  s = strsplit(x, split = attrsep, fixed = TRUE)
  
  # s is a R list obj, use sapply to s, with following anonymous function
  sapply(s, 
         function(atts) {
           
           # split "ID=cds0" like string
           a = strsplit(atts, split = "=", fixed = TRUE)
           
           # use slice function to slice a by sapply, then match it with field
           m = match(field, sapply(a, "[", 1))
           
           if (!is.na(m)) {
             rv = a[[m]][2]
           }
           else {
             rv = as.character(NA)
           }
           return(rv)
         }
  )
  
}


#-------------------------------------------------------
# add gene attributes to other non-gene instances, like CDS, rRNA, tRNA, ...
#-------------------------------------------------------

addGeneAttributesColumn <- function(other_gff, gene_gff){
  
  # add one ID column to gene_gff
  gene_gff[, "ID"] <- rep(NA, nrow(gene_gff))
  for (i in 1:nrow(gene_gff)){
    ID <- getAttributeField(x = gene_gff[i,]$attributes, field = "ID")
    gene_gff[i, "ID"] <- ID
  }
  
  # add one geneAttributes column to other_gff
  other_gff[, "geneAttributes"] <- rep(x=NA, times=nrow(other_gff))
  for (i in 1:nrow(other_gff)) 
  {
    parent_ID <- getAttributeField(x=other_gff[i, "attributes"], "Parent")
    if (is.na(parent_ID)) 
    { 
      other_gff[i, "geneID"] <- as.character(NA)
      other_gff[i, "geneAttributes"] <- as.character(NA)
    } else if (!startsWith(parent_ID, "gene")) {
      other_gff[i, "geneID"] <- as.character(NA)
      other_gff[i, "geneAttributes"] <- as.character(NA)
    } else {
      other_gff[i, "geneID"] <- parent_ID
      other_gff[i, "geneAttributes"] <- gene_gff[gene_gff$ID == parent_ID, "attributes"]
    }
  }
  #print(other_gff[i, ])
  return(other_gff)
}
```

## Input files

```{r}
## set working directory
outdir <- file.path(workdir, "output_all_2", fsep = "/")
gff_file <- "/Users/randuan/Documents/USC/synecho/transcriptomes/10_DE_analysis_YX04-1/YX04-1.gff"
count_file=paste(workdir, "featureCounts_result_2.csv", sep="/")
metadata_file=paste(workdir, "metadata_YX_2.tsv", sep="/")
if (workdir != getwd()) system(paste("mkdir -p", workdir, sep=" "))
setwd(workdir)
if (!dir.exists(outdir)) {
    dir.create(outdir)
} else {
    cat("\n==>", as.character(Sys.time()),  "Output directory ", outdir, "exists, will use it.\n")
}
prefix ="YX04_1"
prefix <- paste(outdir, prefix, sep="/")
```

## GFF annotation file preprocessing

```{r}

# read in gff file
gff <- gffReader(gff_file)
#View(gff)

# get gene_gff
gene_gff <- gff[gff$feature =="gene", ]
#fix(gene_gff)
#View(gene_gff)

# only keep features that are not "gene", 
otherFeatures <- unique(gff[, 3])
#otherFeatures

# get other_gff
other_gff <- data.frame(seqname=character(0), source=character(0), feature=character(0), 
                        start=integer(0), end=integer(0), score=character(0), 
                        strand=character(0), frame=character(0), atrributes=character(0))
for (i in 1:length(otherFeatures)){
  #print(otherFeatures[i])
  other_gff <- rbind(other_gff, gff[gff$feature == otherFeatures[i], ])
}
#fix(other_gff)

# bind geneAttributesColumn and geneID to other_gff
other_gff <- addGeneAttributesColumn(other_gff, gene_gff)
Name <- getAttributeField(other_gff[, "attributes"], "Name", attrsep = ";")
locus_tag <- getAttributeField(other_gff[, "attributes"], "locus_tag", attrsep = ";")
other_gff <- cbind(other_gff, locus_tag=locus_tag, Name=Name)
#head(other_gff)
#View(other_gff)

# extract product, make annotations
product <- getAttributeField(other_gff[, "attributes"], "product", attrsep = ";")
dbxref <- getAttributeField(other_gff[, "attributes"], "dbxref", attrsep = ";")
note <- getAttributeField(other_gff[, "attributes"], "note", attrsep = ";")
annotations <- other_gff[, c("Name", "locus_tag", "seqname", "feature", "start", "end", "strand", "attributes")]
annotations <- cbind(annotations, product, dbxref, note)
# reorganize the order of product column
annotations <- annotations[, c("Name", "locus_tag", "feature", "start", "end", "strand", "seqname", "product", "dbxref", "note", "attributes")]
write.csv(annotations, "G:\\USC\\synecho\\10_DE_analysis_YX04-1\\annotations.csv", row.names = FALSE)
write.csv(other_gff, "G:\\USC\\synecho\\10_DE_analysis_YX04-1\\other_gff.csv", row.names = FALSE)
annotations <- read.csv(file="G:\\USC\\synecho\\10_DE_analysis_YX04-1\\annotations.csv")
#View(annotations)
#head(annotations)
cat("\n==>", as.character(Sys.time()), "final annotations look like: \n")
head(annotations, 2)
```

## Count table preprocessing

```{r}
rawCounts <- read.csv(file = "featureCounts_result_2.csv", header = T,check.names = F,na.string=0)
#fix(rawCounts)
#head(rawCounts)
#ncol(rawCounts)

# get counts table
rawTable <- rawCounts[, 7:ncol(rawCounts)]
rownames(rawTable) <- rawCounts[, 1]
#head(rawTable)
counts <- sapply(rawTable, as.numeric)
rownames(counts) <- rownames(rawTable)
cat("\n==>", as.character(Sys.time()), " raw count table looks like: \n")
head(counts, 2)
```

### filter out weakly expressed genes and rRNAs/tRNAs

```{r}
# calculate count per million
counts[is.na(counts)] <- 0
cpms <- cpm(counts)
#head(cpms)
cat("\n==>", as.character(Sys.time()), " Dimension before filtering: ", dim(cpms), "\n")

# keep rows meet requirements: at least 1 column has cpm more than 1, rowSums more than 0.5*ncol
keep <- rowSums(cpms > 1) >=1 & rowSums(cpms) >= ncol(cpms)*0.5
counts <- counts[keep, ]
cat("\n==>", as.character(Sys.time()), " Dimension after filtering weakly expressed genes: ", dim(counts), "\n")

# remove rows belongs to rRNA and tRNA
#View(other_gff)
remove <- other_gff[other_gff$feature == "rRNA" | other_gff$feature == "tRNA", "geneID"]
#remove

counts <- counts[!row.names(counts)%in%remove, ]
#head(counts)
#dim(counts)
cat("\n==>", as.character(Sys.time()), " Dimension after removing and weakly expressed genes and rRNA/tRNA: ", dim(counts))
#View(counts)
```

### read in metadata

```{r}
cat("\n==>", as.character(Sys.time()), " making metatable ...\n")
# build a meta table, giving all experimental factors
#colnames(counts)

# read in metadata
metadata <- read.table(metadata_file, header = TRUE, as.is = TRUE, stringsAsFactors = FALSE, row.names = 1)
if(!all.equal(rownames(metadata), colnames(counts))) {
  stop("sample names in metadata didn't match column names in count table!\n")
}
cat("\n==>", as.character(Sys.time()), " metadata looks like: \n")
head(metadata)
```

### get normalized counts

```{r}
cat("\n==>", as.character(Sys.time()), " running edgeR TMM normalization ...\n")
# make DGEList
cat("\n==>", as.character(Sys.time()), " making DEGList with counts and metadata ...\n")
d <- DGEList(counts=counts, group=as.factor(metadata$treatment_temp))
#d
cat("\n==>", as.character(Sys.time()), " calculating normalization factors using TMM method ...\n")
d <- calcNormFactors(d, method = "TMM")
#d
cat("\n==>", as.character(Sys.time()), " calculating count per million (cpm) using normalized DGEList object ...\n")
cpms<- cpm(d, normalized.lib.sizes=TRUE)
#head(cpms)
cat("\n==>", as.character(Sys.time()), " formating cpm counts to scientific format with 2 digits ...\n")
cpms.formatted <- format(cpms, digits=2, scientific = F)
colnames(cpms.formatted) <- paste(colnames(cpms.formatted), "_CPM", sep = "")
cat("\n==>", as.character(Sys.time()), " formated cpm looks like this:\n")
head(cpms.formatted, 2)

# compute log2CPM
cat("\n==>", as.character(Sys.time()), " computing log2 transformed cpms ...\n")
cpms.log <- log2(cpms+1)
cpms.log.formatted <- format(cpms.log, digits=2, scientific = F)
colnames(cpms.log.formatted) <- paste(colnames(cpms), "_logCPM", sep = "")
cat("\n==> formated logCPM looks like this:\n")
head(cpms.log.formatted, 2)

cat("\n==>", as.character(Sys.time()), " writing out cpms ...\n")
# annotate the cpm table, then write it out with annotations
rawCounts.selected <- rawTable[rownames(cpms), ]
#head(rawCounts.selected)
colnames(rawCounts.selected) <- paste(colnames(rawCounts.selected), "_RAW", sep = "")
#head(rawCounts.selected)
rawCount_cpms <- cbind(rawCounts.selected, cpms.formatted, cpms.log.formatted)
#head(rawCount_cpms)
annotations.selected <- annotations[annotations$locus_tag%in%rownames(rawCount_cpms), ]
#View(annotations.selected)
rownames(annotations.selected) <- annotations.selected$locus_tag
anno_cols <- c('locus_tag', 'Name', 'feature', 'start', 'end', 'strand', 'seqname', 'product', 'note', 'dbxref')
annotations.selected <- annotations.selected[rownames(cpms.formatted), anno_cols]
#head(annotations.selected)
rawCount_cpms.anno <- cbind(rawCount_cpms, annotations.selected)
#head(rawCount_cpms.anno)
write.table(rawCount_cpms, file=paste(prefix, "_featureCounts_CPM.tsv", sep=""), sep="\t", row.names = T, col.names=NA)
write.table(rawCount_cpms.anno, file=paste(prefix, "_featureCounts_CPM_anno.tsv", sep=""), sep="\t", row.names = T, col.names=NA)

#pdf(file = paste(prefix, "_featureCounts_top1000_logCPM.pdf", sep="")) 
pheatmap(cpms.log[1:1000, ], cluster_cols = F)
#dev.off()
```

## Differential Expression Analysis

```{r}

# Calculate TPM
# michael's version
# https://support.bioconductor.org/p/91218/
tpm3 <- function(counts,len) {
  x <- counts/len
  return(t(t(x)*1e6/colSums(x)))
}
```

### construct DESeqDataSet object

```{r}
library(DESeq2)
library(ggplot2)

cat("\n==>", as.character(Sys.time()), " importing counts and metadata into DESeq: \n")
dds <- DESeqDataSetFromMatrix(countData = counts,
                              colData = metadata,
                              design= ~ treatment_temp)
```

### check read number per sample

```{r}
cat("\n==>", as.character(Sys.time()), " total read number per sample are ... \n")
total_read_no <- as.data.frame(colSums(assay(dds)))
colnames(total_read_no) <- c("TotalReads")
total_read_no <- cbind(total_read_no, metadata[rownames(total_read_no), ])
total_read_no$SampleName <- rownames(total_read_no)
total_read_no

my_theme1 <- theme_bw() + 
  theme(panel.background = element_blank(), 
        axis.line = element_line(colour = "black"), 
        text = element_text(size = 16),
        axis.title.x = element_text(size=18, color="black"), 
        axis.title.y = element_text(size=18, color="black"), 
        axis.text.x = element_text(angle = 0, hjust = 1, color="black"), 
        panel.grid.minor.x = element_line(colour = "grey", size=0.2, linetype = 'dashed'), 
        panel.grid.major.x = element_line(colour = "grey", size=0.2),
        panel.grid.minor.y = element_line(colour = "grey", size = 0.2, linetype = 'dashed'),
        panel.grid.major.y = element_line(colour = "grey", size=0.2),
        legend.position = "bottom", 
        legend.text=element_text(size=10), 
        legend.key.size = unit(1,"line"), 
        plot.margin=unit(c(1,1,1,1),"cm")
       ) 

ggplot(total_read_no, aes(x = SampleName, y = TotalReads, fill = factor(color))) + 
  geom_bar(stat="identity", width=0.5) +
  geom_abline(slope=0, intercept=3e6, col="red",lty=2) +
  scale_fill_manual(values = c("forestgreen", "red", "blue","yellow3", "orange", "purple")) + 
  labs(y = "Total Read Number", x = "Sample") + my_theme1 +
  theme(axis.text.x = element_text(angle = 60, hjust = 1, size=10), axis.text.y = element_text(size=10))
ggsave(filename=paste(prefix, "_sample_read_number_barplot.pdf", sep=""), device="pdf", width=297, height=210, units="mm" )
```

### variance stablizing transformation and regularized logarithm (rlog) transformation

```{r}
cat("\n==>", as.character(Sys.time()), " running vst transformation ... \n")
vsd <- vst(dds, blind=FALSE)
vst_count <- assay(vsd)
cat("\n==>", as.character(Sys.time()), " running rlog transformation ... \n")
rld <- rlog(dds, blind=FALSE)
rlog_count <- assay(rld)
cat("\n==>", as.character(Sys.time()), " vst transformed counts look like: \n")
head(vst_count, 3)
cat("\n==>", as.character(Sys.time()), " rlog transformed counts look like: \n")
head(rlog_count, 3)
# write vst and rlog counts
write.table(vst_count, file=paste(prefix, "_vst_count.tsv", sep=""), sep="\t", row.names = T, col.names=NA)
write.table(rlog_count, file=paste(prefix, "_rlog_count.tsv", sep=""), sep="\t", row.names = T, col.names=NA)
# boxplot of vst and rlog transformed counts

# plot normalized count
library("patchwork")
library("tidyverse")
logCount <- as.data.frame(log10(assay(dds)+1)) %>% rownames_to_column %>% 
      gather(key="SampleName", value="Counts", -rowname)
p_logCount <- ggplot(logCount, aes(x=SampleName, y=Counts)) + 
    geom_boxplot(outlier.colour="black", outlier.shape=1, outlier.size=1)
vst_count.long <- as.data.frame(vst_count) %>%  rownames_to_column %>% 
      gather(key="SampleName", value="Counts", -rowname)
p_vst <- ggplot(vst_count.long, aes(x=SampleName, y=Counts)) + 
    geom_boxplot(outlier.colour="black", outlier.shape=1, outlier.size=1)
rlog_count.long <- as.data.frame(rlog_count) %>%  rownames_to_column %>% 
      gather(key="SampleName", value="Counts", -rowname)
p_rlog <- ggplot(rlog_count.long, aes(x=SampleName, y=Counts)) + 
    geom_boxplot(outlier.colour="black", outlier.shape=1, outlier.size=1)
p <- p_logCount + p_vst + p_rlog
p
ggsave(filename=paste(prefix, "_sample_vst_rlog_norm_boxplot.pdf", sep=""), device="pdf", width=297, height=210, units="mm" )
```

### Exploratory Analysis

#### PCA using `FactoMineR`

```{r}
library(FactoMineR)
library(factoextra)
df_pca <- PCA(t(rlog_count), graph = F)
fviz_pca_ind(X = df_pca, axes = c(1, 2), 
             geom=c("point","text"),
             col.ind = metadata$treatment_temp,
             legend.title = "treatment_temp")
ggsave(filename=paste(prefix, "_sample_vst_rlog_norm_pca.pdf", sep=""), device="pdf", width=297, height=210, units="mm" )
```

#### PCA using `DESeq2`

```{r}

# use ggrepel to label the dots
library(ggrepel)

# PCA based on vsd
#pdf(file = paste(prefix, "_sample_vst_PCA.pdf", sep="")) 
pcaData <- plotPCA(vsd, intgroup=c("treatment_temp"), returnData=TRUE)
percentVar <- round(100 * attr(pcaData, "percentVar"))
ggplot(pcaData, aes(PC1, PC2)) +
  geom_point(aes(color=treatment_temp, shape=as.character(metadata$pch)), size=3) +
  coord_fixed() +
  ggtitle("PCA based on VST counts") + 
  xlab(paste0("PC1: ",percentVar[1],"% variance")) +
  ylab(paste0("PC2: ",percentVar[2],"% variance")) + 
  geom_text_repel(aes(label=rownames(metadata)), size=3) +
  #geom_text(aes(label=rownames(metadata), hjust=0.5, vjust=-0.4)) + 
  scale_color_manual(values=unique(as.character(metadata$color)[order(metadata$treatment_temp)])) + 
  scale_shape_manual(values=unique(as.numeric(metadata$pch)[order(metadata$pch)])) +
  theme_bw() +
  theme(legend.position="bottom")
ggsave(filename=paste(prefix, "_sample_vst_PCA.pdf", sep=""), device="pdf", width=297, height=210, units="mm" )
#dev.off()

# PCA based on rlog
#pdf(file = paste(prefix, "_sample_rlog_PCA.pdf", sep="")) 
pcaData <- plotPCA(rld, intgroup=c("treatment_temp"), returnData=TRUE)
percentVar <- round(100 * attr(pcaData, "percentVar"))
ggplot(pcaData, aes(PC1, PC2)) +
  geom_point(aes(color=treatment_temp, shape=as.character(metadata$pch)), size=3) +
  coord_fixed() +
  ggtitle("PCA based on rlog counts") + 
  xlab(paste0("PC1: ",percentVar[1],"% variance")) +
  ylab(paste0("PC2: ",percentVar[2],"% variance")) +
  geom_text_repel(aes(label=rownames(metadata)), size=3) +
  #geom_text(aes(label=rownames(metadata), hjust=0.5, vjust=-0.4)) +
  scale_color_manual(values=unique(as.character(metadata$color)[order(metadata$treatment_temp)])) + 
  scale_shape_manual(values=unique(as.numeric(metadata$pch)[order(metadata$pch)])) +  
  theme_bw() +
  theme(legend.position="bottom")
ggsave(filename=paste(prefix, "_sample_rlog_PCA.pdf", sep=""), device="pdf", width=297, height=210, units="mm" )
#dev.off()
```

#### sample heatmap

```{r}

library(RColorBrewer)
library(pheatmap)

# clustering using Euclidean distance based on vst/rlog counts
vst_dist <- dist(t(vst_count))
vst_dist_mat <- as.matrix(vst_dist)
rownames(vst_dist_mat) <- paste(colData(dds)$treatment_temp, colData(dds)$replicate, sep = "_")
colnames(vst_dist_mat) <- colData(dds)$Name
rlog_dist <- dist(t(rlog_count))
rlog_dist_mat <- as.matrix(rlog_dist)
rownames(rlog_dist_mat) <- paste(colData(dds)$treatment_temp, colData(dds)$replicate, sep = "_")
colnames(rlog_dist_mat) <- colData(dds)$Name

# plot heatmap
par(mfrow=c(2, 1))
colors <- colorRampPalette(rev(brewer.pal(9, "Blues")))(255)
pheatmap(vst_dist_mat, col=colors, main = "vst Euclidean distance",filename = "/Users/randuan/Documents/USC/synecho/transcriptomes/10_DE_analysis_YX04-1/output_all_2/YX04_1_sample_vst_plot_heatmap.pdf")
pheatmap(rlog_dist_mat, col=colors, main = "rlog Euclidean distance",filename = "/Users/randuan/Documents/USC/synecho/transcriptomes/10_DE_analysis_YX04-1/output_all_2/YX04_1_sample_rlog_plot_heatmap.pdf")
oldpar <- par()
par(oldpar)

```

#### sample dendrogram

```{r}
# clustering using Euclidean distance based on vst counts
vst_dist <- dist(t(vst_count))
# the agglomeration method can be "ward.D", "ward.D2", "single", "complete", 
# "average" (= UPGMA), "mcquitty" (= WPGMA), "median" (= WPGMC) or "centroid" (= UPGMC)
vst_clust <- hclust(vst_dist, method="ward.D2")
vst_dend <- as.dendrogram(vst_clust, hang=0.1)
vst_dend_cols <- as.character(metadata$color[order.dendrogram(vst_dend)])
labels_colors(vst_dend) <- vst_dend_cols
# rotate branches based on leaf order
leaf_order <- c('T23Fe1', 'T23Fe2', 'T23Fe3', 
                'T23noFe1', 'T23noFe2', 'T23noFe3',
                'T27Fe1', 'T27Fe2', 'T27Fe3', 
                'T27noFe1', 'T27noFe2', 'T27noFe3')
if(!all.equal(leaf_order, unique(leaf_order))) {
  stop("sample names should be unique and should contain all the leaf names!\n")
}
vst_dend <- rotate(vst_dend, order=leaf_order)
# save to pdf
pdf(file = paste(prefix, "_sample_vst_dendrogram.pdf", sep="")) 
plot(vst_dend, ylab="Euclidean Distance based on VST counts")
dev.off()

# clustering using Euclidean distance based on rlog counts
rlog_dist <- dist(t(rlog_count))
rlog_clust <- hclust(rlog_dist, method="ward.D2")
rlog_dend <- as.dendrogram(rlog_clust, hang=0.1)
rlog_dend_cols <- as.character(metadata$color[order.dendrogram(rlog_dend)])
labels_colors(rlog_dend) <- rlog_dend_cols
# rotate branches based on leaf order
leaf_order <- c('T23Fe1', 'T23Fe2', 'T23Fe3', 
                'T23noFe1', 'T23noFe2', 'T23noFe3',
                'T27Fe1', 'T27Fe2', 'T27Fe3', 
                'T27noFe1', 'T27noFe2', 'T27noFe3')
if(!all.equal(leaf_order, unique(leaf_order))) {
  stop("sample names should be unique and should contain all the leaf names!\n")
}
rlog_dend <- rotate(rlog_dend, order=leaf_order)
pdf(file = paste(prefix, "_sample_rlog_dendrogram.pdf", sep="")) 
plot(rlog_dend, ylab="Euclidean Distance based on rlog counts")
dev.off()

par(mfrow=c(2, 1))
plot(vst_dend, ylab="Euclidean Distance based on VST counts")
plot(rlog_dend, ylab="Euclidean Distance based on rlog counts")
oldpar <- par()
par(oldpar)
```

#### PCoA using `PhyloSeq`

```{r}
# making our phyloseq object with transformed table from vst count
vst_count_phy <- otu_table(vst_count, taxa_are_rows=T)
metadata_phy <- sample_data(metadata)
vst_phyloseq <- phyloseq(vst_count_phy, metadata_phy)
vst_pcoa <- ordinate(vst_phyloseq, method="MDS", distance="euclidean")
# eigen_vals allows us to scale the axes according to their magnitude of separating apart the samples
eigen_vals <- vst_pcoa$values$Eigenvalues 
plot_ordination(vst_phyloseq, vst_pcoa) + 
  geom_point(aes(color=treatment_temp, shape=as.character(metadata$pch)), size=3) + 
  labs(col="treatment_temp") +
  geom_text_repel(aes(label=rownames(metadata)), size=3) +
  coord_fixed(sqrt(eigen_vals[2]/eigen_vals[1])) + ggtitle("PCoA based on VST counts") + 
  scale_color_manual(values=unique(as.character(metadata$color)[order(metadata$treatment_temp)])) + 
  scale_shape_manual(values=unique(as.numeric(metadata$pch)[order(metadata$pch)])) +  
  theme_bw() +
  theme(legend.position="bottom")
ggsave(filename=paste(prefix, "_sample_vst_PCoA.pdf", sep=""), device="pdf", width=297, height=210, units="mm" )

# making our phyloseq object with transformed table from rlog count
rlog_count_phy <- otu_table(rlog_count, taxa_are_rows=T)
metadata_phy <- sample_data(metadata)
rlog_phyloseq <- phyloseq(rlog_count_phy, metadata_phy)
rlog_pcoa <- ordinate(rlog_phyloseq, method="MDS", distance="euclidean")
eigen_vals <- rlog_pcoa$values$Eigenvalues
plot_ordination(rlog_phyloseq, rlog_pcoa) + 
  geom_point(aes(color=treatment_temp, shape=as.character(metadata$pch)), size=3) + 
  labs(col="treatment_temp") +
  geom_text_repel(aes(label=rownames(metadata)), size=3) +
  coord_fixed(sqrt(eigen_vals[2]/eigen_vals[1])) + ggtitle("PCoA based on rlog counts") + 
  scale_color_manual(values=unique(as.character(metadata$color)[order(metadata$treatment_temp)])) + 
  scale_shape_manual(values=unique(as.numeric(metadata$pch)[order(metadata$pch)])) +  
  theme_bw() +
  theme(legend.position="bottom")
ggsave(filename=paste(prefix, "_sample_rlog_PCoA.pdf", sep=""), device="pdf", width=297, height=210, units="mm" )
```

### DE based on treatment

```{r}
# function to write DE tables
write_DE_tables <- function(contrast, suffix_str){
  contrast <- contrast[order(contrast$padj<0.05, decreasing=F),]
  anno <- rawCount_cpms.anno[rownames(contrast), ]
  contrast.anno <- cbind(contrast, anno)
  write.table(contrast, file=paste(prefix, suffix_str, ".tsv", sep=""), sep="\t", row.names = T, col.names=NA)
  write.table(contrast.anno, file=paste(prefix, suffix_str, "_anno.tsv", sep=""), sep="\t", row.names = T, col.names=NA)
  write.table(contrast.anno[contrast$padj < 0.05 & contrast$log2FoldChange>=1, ], file=paste(prefix, suffix_str, "_anno_up_sig.tsv", sep=""), sep="\t", row.names = T, col.names=NA)
  write.table(contrast.anno[contrast$padj < 0.05 & contrast$log2FoldChange<=-1, ], file=paste(prefix, suffix_str, "_anno_dn_sig.tsv", sep=""), sep="\t", row.names = T, col.names=NA)
  write.table(contrast.anno[(contrast$log2FoldChange>=1 | contrast$log2FoldChange <= -1), ], file=paste(prefix, suffix_str, "_anno_sig.tsv", sep=""), sep="\t", row.names = T, col.names=NA)
}


# construct DESeqDataSet object
dds <- DESeqDataSetFromMatrix(countData = counts,
                              colData = metadata,
                              design= ~ treatment_temp)

# set the baseline treatment as the "LFe_19" treatment
dds$treatment <- relevel(dds$treatment_temp, ref = "HFe_27")

# run deseq standard analysis
design(dds) <- ~treatment_temp
dds.treatment_temp <- DESeq(dds)
# extract size factors
size_facctors <- sizeFactors(dds.treatment_temp)
size_facctors

# pulling out our results table, 
# we specify the object, the p-value we are going to use to filter our results, 
# and what contrast we want to consider by first naming the column, then the two groups we care about 

# LFe23 vs HFe23 samples
LFe23_vs_HFe23_contrast <- results(dds.treatment_temp, alpha=0.05, contrast=c("treatment_temp", "LFe_23", "HFe_23"))
#head(LFe23 vs HFe23_contrast)
write_DE_tables(LFe23_vs_HFe23_contrast, "_LFe23_vs_HFe23_contrast")

# LFe27 vs HFe27 samples
LFe27_vs_HFe27_contrast <- results(dds.treatment_temp, alpha=0.05, contrast=c("treatment_temp", "LFe_27", "HFe_27"))
#head(HFe27_vs_LFe27_contrast)
write_DE_tables(LFe27_vs_HFe27_contrast, "_LFe27_vs_HFe27_contrast")

# LFe27 vs LFe23 samples
LFe27_vs_LFe23_contrast <- results(dds.treatment_temp, alpha=0.05, contrast=c("treatment_temp", "LFe_27", "LFe_23"))
#head(LFe27_vs_LFe23_contrast)
write_DE_tables(LFe27_vs_LFe23_contrast, "_LFe27_vs_LFe23_contrast")

# HFe27 vs HFe23 samples
HFe27_vs_HFe23_contrast <- results(dds.treatment_temp, alpha=0.05, contrast=c("treatment_temp", "HFe_27", "HFe_23"))
#head(HFe27_vs_HFe23_contrast)
write_DE_tables(HFe27_vs_HFe23_contrast, "_HFe27_vs_HFe23_contrast")

# LFe27 vs HFe23 samples
LFe27_vs_HFe23_contrast <- results(dds.treatment_temp, alpha=0.05, contrast=c("treatment_temp", "LFe_27", "HFe_23"))
#head(LFe27_vs_LFe23_contrast)
write_DE_tables(LFe27_vs_HFe23_contrast, "_LFe27_vs_HFe23_contrast")

# HFe27 vs LFe23 samples
HFe27_vs_LFe23_contrast <- results(dds.treatment_temp, alpha=0.05, contrast=c("treatment_temp", "HFe_27", "LFe_23"))
#head(HFe27_vs_LFe23_contrast)
write_DE_tables(HFe27_vs_LFe23_contrast, "_HFe27_vs_LFe23_contrast")

# we can get a glimpse at what this table currently holds with the summary command
summary(LFe23_vs_HFe23_contrast)
summary(LFe27_vs_HFe27_contrast)
summary(LFe27_vs_LFe23_contrast)
summary(HFe27_vs_HFe23_contrast)
summary(LFe27_vs_HFe23_contrast)
summary(HFe27_vs_LFe23_contrast)

# Function to extract necessary statistics (e.g., count of upregulated and downregulated genes)
extract_stats <- function(contrast) {
    # Example: Assuming 'contrast' contains a column 'padj' for adjusted p-values 
    # and 'log2FoldChange' for log fold changes
    # Adapt this based on your actual data structure
    upregulated <- sum(contrast$padj < 0.05 & contrast$log2FoldChange >= 1, na.rm = TRUE)
    downregulated <- sum(contrast$padj < 0.05 & contrast$log2FoldChange <= -1, na.rm = TRUE)
    return(c(up = upregulated, down = downregulated))
}

# Aggregating stats from each contrast
DE_stats <- data.frame(
    contrast = c("LFe23_vs_HFe23", "LFe27_vs_HFe27", "LFe27_vs_LFe23", "HFe27_vs_HFe23", "LFe27_vs_HFe23", "HFe27_vs_LFe23"),
    t(sapply(list(LFe23_vs_HFe23_contrast, LFe27_vs_HFe27_contrast, LFe27_vs_LFe23_contrast, HFe27_vs_HFe23_contrast, LFe27_vs_HFe23_contrast, HFe27_vs_LFe23_contrast), extract_stats))
)

# Preparing data for heatmap
mat <- DE_stats[, c("up", "down")]
rownames(mat) <- DE_stats$contrast

# Save heatmap to PDF
pdf(file = paste(prefix, "_DESeq2_DE_Overview.pdf", sep=""))
pheatmap(mat=mat, angle_col = 0, fontsize_col = 10, fontsize_row = 10)
dev.off()

# Display heatmap
pheatmap(mat=mat, angle_col = 0, fontsize_col = 10, fontsize_row = 10)

# Write the DE_stats data frame to a CSV file
write.csv(DE_stats, file = "DE_gene_counts.csv", row.names = FALSE)

```

```{r}
#making barplot for DE numbers
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(tidyr)

# Read the data
de_gene_counts <- read.csv("/Users/randuan/Documents/USC/synecho/transcriptomes/10_DE_analysis_YX04-1/output_all_2/DE_gene_counts.csv")

# Transform the data: make downregulated counts negative
de_gene_counts <- de_gene_counts %>%
  mutate(down = -down)

# Reshape the data
long_de_gene_counts <- gather(de_gene_counts, key = "category", value = "count", up, down)

# Ensure the ordering of the treatments is as in the table
long_de_gene_counts$treatment <- factor(long_de_gene_counts$treatment, levels = unique(de_gene_counts$treatment))

# Create the barplot
DE_gene_counts_plot <- ggplot(long_de_gene_counts, aes(x = treatment, y = count, fill = category)) +
    geom_bar(stat = "identity", position = position_stack(), width = 0.5) +
    geom_text(aes(label = abs(count)), 
              vjust = ifelse(long_de_gene_counts$count > 0, -0.5, 1.5), 
              position = position_stack(vjust = 0.5),
              size = 5, fontface = "bold", color = "white", check_overlap = TRUE) +
    theme_minimal(base_size = 15) +
    theme(panel.background = element_rect(fill = "white"),
          axis.line.y = element_line(color = "black"),
          axis.text.x = element_text(angle = 45, hjust = 1, size = 25, face = "bold"),
          axis.text.y = element_text(size = 25, face = "bold")) +
    labs(x = "Treatment", y = "Gene Count", title = "Upregulated and Downregulated Gene Counts by Treatment") +
    scale_fill_manual(values = c("up" = "firebrick3", "down" = "navy"))

# Specify the file path
file_path <- "/Users/randuan/Documents/USC/synecho/transcriptomes/10_DE_analysis_YX04-1/output_all_2/DE_gene_counts_plot.tif"

# Open a TIFF graphics device
tiff(file_path, width = 11, height = 8, units = "in", res = 300)

# Plot
print(DE_gene_counts_plot)

# Turn off the device
dev.off()


```

```{r}
#data preparation for KEGG enrichment
rm(list = ls())

# Load necessary libraries
library(readr)
library(readxl)
library(dplyr)
library(clusterProfiler)
library(enrichplot)
library(data.table)
library(tidyr)
library(stringr)
library(magrittr)
library(tidyverse)
library(enrichplot)
library(ggplot2)
library(scales)

# get the necessary information from the ko annotation file and prepare for the universe file

# read the data
ko_data <- read.csv("/Users/randuan/Documents/USC/synecho/transcriptomes/10_DE_analysis_YX04-1/output_all_2/FC2/ko_annotation_YX.csv")

#get columns 1 (id) and 2 (KO terms)
kegg_data <- ko_data[c(1,2)]

#clean the data and expand, since some genes/proteins will have multiple assigned ko terms
#kegg_data$KEGG_ko <- gsub("-", " ", kegg_data$KEGG_ko)
#kegg_data$KEGG_ko <- gsub("ko:", "", kegg_data$KEGG_ko)
#kegg_data$KEGG_ko <- gsub(",ko:", ",", kegg_data$KEGG_ko)
#kegg_1 <- kegg_data %>%
#  separate_rows(KEGG_ko, sep = ",")

# select the needed columns
universe <- kegg_data[,c(1,2)]%>%
  pull(KO)

# Get a list of all files to analyze
files_to_analyze <- list.files(path = "/Users/randuan/Documents/USC/synecho/transcriptomes/10_DE_analysis_YX04-1/output_all_2/FC2/", pattern = "*.tsv", full.names = TRUE)

# Initialize a list to store enrichment results
enrichment_results <- list()

# Loop over each file
for (file in files_to_analyze) {
    # Read the gene data
    genes_data <- read_tsv(file, col_names = TRUE)
    
    # Read the Excel file
ko_data <- read.csv("/Users/randuan/Documents/USC/synecho/transcriptomes/10_DE_analysis_YX04-1/output_all_2/FC2/ko_annotation_YX.csv") 

# Extract the relevant columns
# Assuming the gene names are in the first column of both files and KEGG_ko is a named column in the Excel file
genes_data <- genes_data %>% select(Gene = 1) # Replace '1' with the actual column name if different
KEGG_ko_all <- ko_data %>% select(Gene = 1, KO) # Adjust column indices/names as needed

# Merge the data frames based on the gene names
gene_ko <- merge(genes_data, KEGG_ko_all, by = "Gene")

#clean the data and expand, since some genes/proteins will have multiple assigned ko terms
#gene_ko$KEGG_ko <- gsub("ko:", "", gene_ko$KEGG_ko)
#gene_ko$KEGG_ko <- gsub(",ko:", ",", gene_ko$KEGG_ko)
#gene_ko$KEGG_ko <- gsub("-", " ", gene_ko$KEGG_ko)
gene_ko <- gene_ko %>%
  #separate_rows(KEGG_ko, sep = ",") %>%
  pull(KO)

#run KEGG enrichment
enr_res <- enrichKEGG(gene_ko, universe = universe, organism = "ko", pvalueCutoff = 1, pAdjustMethod = "BH", qvalueCutoff = 1)

# Store the result
    enrichment_results[[file]] <- enr_res
}

####################################################


##create bar plot
output_folder <- "/Users/randuan/Documents/USC/synecho/transcriptomes/10_DE_analysis_YX04-1/output_all_2/FC2/KEGG_enrich/"
dir.create(output_folder, recursive = TRUE)  # This will create the folder if it doesn't exist

plot_list <- list()  # Initialize an empty list to store plots

# Get a list of all files to analyze
files_to_analyze <- list.files(path = "/Users/randuan/Documents/USC/synecho/transcriptomes/10_DE_analysis_YX04-1/output_all_2/FC2/", pattern = "*.tsv", full.names = TRUE)

# Loop over each enrichment result
for (i in seq_along(enrichment_results)) {
    # Extract the base name of the file (without extension) for use in the plot title and filename
    file_base_name <- tools::file_path_sans_ext(basename(files_to_analyze[i]))
  
    # Convert the result to a data frame
    enrich_df <- as.data.frame(enrichment_results[[i]])

    # Order by p.adjust and select the top 10
    top_enrich_df <- enrich_df %>%
                      arrange(p.adjust) %>%
                      head(10) %>%
                      mutate(label_color = ifelse(p.adjust < 0.5, "firebrick3", "black"))

    # Create the bar plot with labels
plot_title <- paste("Top 10 KEGG Enrichment Results for", file_base_name)
p <- ggplot(top_enrich_df, aes(x = reorder(Description, -p.adjust), y = Count)) +
  geom_bar(stat = "identity", width = 0.5) +
  coord_flip() +  # Flip coordinates to have the highest count on top
  geom_text(aes(label = paste(Count, "(", round(p.adjust, 3), ")"), color = label_color),
            hjust = -0.1, size = 5) +  # Adjust hjust as needed
  expand_limits(y = c(0, max(top_enrich_df$Count) * 1.2)) +   # Adjust the y-axis limits
  scale_color_identity() +  # Tell ggplot2 to use the actual color names
  labs(title = plot_title, x = "Pathway", y = "Count") +
  theme_minimal() +
  theme(axis.title = element_text(size = 20, face = "bold"),
        axis.text = element_text(size = 18, face = "bold"),
        plot.title = element_text(size = 16, face = "bold"),
        axis.text.x = element_text(color = "black"),  # Ensure axis text is black
        axis.text.y = element_text(color = "black"),
        legend.position = "none")  # Remove legend for colors

    # Save the plot
    plot_filename <- paste0(file_base_name, "_KEGG_Enrichment.jpg")
    full_path <- file.path(output_folder, plot_filename)
    ggsave(full_path, p, width = 15, height = 8, device = "jpeg")
}

####################################################
# Create a dot plot
dotplot(enr_res)

```

```{r}
#combine all the differential genes and annotation together into one table
library(readr)
library(dplyr)
library(tidyr)

# Define the path to the folder containing the files
folder_path <- "/Users/randuan/Documents/USC/synecho/transcriptomes/10_DE_analysis_YX04-1/output_all_2/FC2"

# Get a list of all file names in the folder
file_names <- list.files(path = "/Users/randuan/Documents/USC/synecho/transcriptomes/10_DE_analysis_YX04-1/output_all_2/FC2/", pattern = "*.tsv", full.names = TRUE)

# Initialize an empty vector to store the first column from each file
all_first_columns <- list()

# Loop over each file to read the first column
for (file in file_names) {
    # Read only the first column
    # Assuming the files have headers, and the first column is named
    DEGs <- read_tsv(file, col_names = FALSE, col_types = cols(column1 = col_character()), col_select = 1)
    
    # Append the first column to the vector
    # Assuming the first column is named 'column1'
    all_first_columns <- rbind(all_first_columns, DEGs)
}

# Remove duplicate names
DEGs_all <- unique(all_first_columns)
# Remove rows with NA in any column
DEGs_all <- DEGs_all %>% 
  filter_all(all_vars(!is.na(.)))
DEGs_all <- DEGs_all %>% 
  rename(id = 1)

#combine the eggnog annotation and ko annotation with all DEGs
eggnog_data <- read.csv("/Users/randuan/Documents/USC/synecho/transcriptomes/10_DE_analysis_YX04-1/output_all_2/FC2/eggnog_results.csv")
ko_data <- read.csv("/Users/randuan/Documents/USC/synecho/transcriptomes/10_DE_analysis_YX04-1/output_all_2/FC2/ko_annotation_YX.csv")

combined_data <- DEGs_all %>%
  left_join(eggnog_data %>% select(id = 1, Description, Preferred_name, KEGG_Pathway), by = "id")
combined_data <- combined_data %>%
  left_join(ko_data %>% select(id = 1, KO, Definition), by = "id")
combined_data <- combined_data %>%
  separate(Definition, into = c("ko_name", "ko_description"), sep = ";")

#write out the annotation table
write.csv(combined_data, "/Users/randuan/Documents/USC/synecho/transcriptomes/10_DE_analysis_YX04-1/output_all_2/FC2/annotated/DEG_anno_YX_1.csv", row.names = FALSE)

```
```{r}
#find out all the genes to be plotted in each pathway
#put all the log2FoldChange in one table
#making heatmap for each pathway
library(readr)
library(dplyr)
library(tidyr)
library(pheatmap)

# Set the path to the directory containing the files
folder_path <- "/Users/randuan/Documents/USC/synecho/transcriptomes/10_DE_analysis_YX04-1/output_all_2/FC2/annotated"

# List all files with '_contrast_anno.tsv' in the filenames
file_list <- list.files(path = folder_path, pattern = "_contrast_anno.tsv$", full.names = TRUE)

# Function to read each file, extract required columns, and add a file name column
read_and_extract <- function(file_path) {
  # Extract the base name without the ending '_contrast_anno.tsv'
  base_name <- gsub("_contrast_anno\\.tsv$", "", basename(file_path))
  
  # Read the file
  df <- read_tsv(file_path, col_types = cols_only(
    id = col_character(),  # Adjust 'gene_name' to the actual name of your first column
    log2FoldChange = col_double() # Adjust 'Log2FoldChange' to the actual name if different
  ))
  
  # Extract the gene name and Log2FoldChange columns
  df <- df %>% 
    transmute(id, log2FoldChange) %>%
    rename(!!base_name := log2FoldChange)  # Renames the Log2FoldChange column to the file name
  
  return(df)
}

# Read all files and create a list of data frames
data_list <- lapply(file_list, read_and_extract)

# Combine all data frames into one based on gene names
combined_data <- reduce(data_list, full_join, by = "id")

#write out the table with all the log2FoldChange in all the comparisons
write.csv(combined_data, "/Users/randuan/Documents/USC/synecho/transcriptomes/10_DE_analysis_YX04-1/output_all_2/FC2/annotated/log2FC_all.csv", row.names = FALSE)

```


```{r}
#make heatmap for all the DEGs
install.packages("readxl")
library(dplyr)
library(pheatmap)
library(readxl)

# Read the CSV files into R
deg_anno_yx_1 <- read.csv("/Users/randuan/Documents/USC/synecho/transcriptomes/10_DE_analysis_YX04-1/output_all_2/FC2/annotated/DEG_anno_YX_1.csv", stringsAsFactors = FALSE)
log2fc_all <- read_excel("/Users/randuan/Documents/USC/synecho/transcriptomes/10_DE_analysis_YX04-1/output_all_2/FC2/annotated/log2FC_all.xlsx")

#log2fc_all <- read.csv("/Users/randuan/Documents/USC/synecho/transcriptomes/10_DE_analysis_YX04-1/output_all_2/FC2/annotated/log2FC_all.csv", stringsAsFactors = FALSE)

# Merge the two dataframes based on the first column
# Assuming the first column is named 'id' in both dataframes
combined_data <- merge(deg_anno_yx_1, log2fc_all, by = "id")

heatmap_data <- as.matrix(combined_data[, 8:13])

# Define color scale
colors <- colorRampPalette(c("navy", "white", "firebrick3"))(100)

# Create the heatmap without clustering and with specified color scale
p <- pheatmap(heatmap_data, 
              cluster_rows = TRUE, 
              cluster_cols = FALSE, 
              show_rownames = FALSE, 
              show_colnames = TRUE, 
              color = colors,
              breaks = seq(-5, 5, length.out = 101),
              main = "Heatmap of Combined Data",
              cellwidth = 30,
              cellheight = 0.5,
              fontsize_row = 10,
              fontsize_col = 12,
              angle_col = 45,
              border_color = "grey",  # Set border lines color
              )

# Save the heatmap to a file
output_dir <- "/Users/randuan/Documents/USC/synecho/transcriptomes/10_DE_analysis_YX04-1/output_all_2/FC2/annotated"  # Specify your output directory
file_path <- file.path(output_dir, "DEGs_heatmap.jpeg")
ggsave(file_path, plot = p, width = 15, height = 15, units = "in", dpi = 600)


```

```{r}
#make table for top 20 DEGs in each comparison
library(dplyr)
library(tidyr)

# Initialize a list to store the top and bottom 20 values from each column
combined_results <- list()

# Loop through columns 8 to 13
for (i in 8:13) {
    column_name <- names(combined_data)[i]

    # Find top 20 highest values
    top_values <- combined_data %>%
                  arrange(desc(.[[i]])) %>%
                  head(20) %>%
                  select(Column6 = 6, Value = i)

    # Find top 20 lowest values
    bottom_values <- combined_data %>%
                     arrange(.[[i]]) %>%
                     head(20) %>%
                     select(Column6 = 6, Value = i)

    # Combine top and bottom values
    combined <- rbind(top_values, bottom_values) %>%
                mutate(Column = column_name)

    # Add to the results list
    results_list[[i-7]] <- combined
}

# Combine all results side-by-side
final_results <- do.call(cbind, results_list)

write.csv(final_results, "/Users/randuan/Documents/USC/synecho/transcriptomes/10_DE_analysis_YX04-1/output_all_2/FC2/annotated/top20.csv", row.names = FALSE)

```



```{r}
#making heatmaps
# Set the path to the directory containing the CSV files
folder_path <- "/Users/randuan/Documents/USC/synecho/transcriptomes/10_DE_analysis_YX04-1/output_all_2/FC2/annotated/pathway"

# List all CSV files in the folder
csv_files <- list.files(path = folder_path, pattern = "\\.csv$", full.names = TRUE)

# Assuming 'combined_data' is your main data frame and the first column is named 'id'
combined_data <- combined_data %>% select(id, everything())

# Initialize a list to store the merged data frames
merged_data_list <- list()

# Function to read each CSV file and merge it with combined_data
process_file <- function(file_path) {
  # Read the file
  df <- read_csv(file_path)

  # Merge with combined_data based on 'id'
  merged_df <- df %>% inner_join(combined_data, by = "id")

  return(merged_df)
}

# Read and process each file, storing the result in merged_data_list with the file's base name as the key
for (file_path in csv_files) {
  file_base_name <- tools::file_path_sans_ext(basename(file_path))
  merged_data_list[[file_base_name]] <- process_file(file_path)
}

#making heatmap

# Define the output directory
output_dir <- "/Users/randuan/Documents/USC/synecho/transcriptomes/10_DE_analysis_YX04-1/output_all_2/FC2/annotated/pathway"

#create labels using column 2 and 3
merged_data_list <- lapply(merged_data_list, function(df) {
  df %>%
    mutate(Combined = paste(df[[2]], df[[3]], sep = "  "))
})

# Loop through each dataframe in the list
for (df_name in names(merged_data_list)) {
    # Extract the dataframe
    df <- merged_data_list[[df_name]]

    # Use the content of column 10 for row labels
    row_labels <- as.matrix(df[, 16])
    
    # Add a column of 0s after column 5 and column 7
    #df <- df %>%
          #mutate(zero_after_5 = 0, zero_after_7 = 0) %>%
          #select(1:5, zero_after_5, 6:7, zero_after_7, 8:11)
    
    # Select columns 4 to 9 for heatmap data
    heatmap_data <- as.matrix(df[, 10:15])

    # Define color scale
    colors <- colorRampPalette(c("navy", "white", "firebrick3"))(100)

    # Create the heatmap without clustering and with specified color scale
    p <- pheatmap(heatmap_data, 
                  cluster_rows = FALSE, 
                  cluster_cols = FALSE, 
                  show_rownames = TRUE, 
                  show_colnames = TRUE, 
                  color = colors,
                  breaks = seq(-5, 5, length.out = 101),
                  main = paste(" ", df_name),
                  cellwidth = 30,
                  cellheight = 15,
                  fontsize_row = 10,
                  fontsize_col = 12,
                  angle_col = 45,
                  display_numbers=ifelse(abs(heatmap_data) > 1, "*", ""),
                  border_color = "grey",  # Remove border lines
                  labels_row = row_labels)

    # Save each heatmap to a file in the specified directory
    file_path <- file.path(output_dir, paste0(df_name, "_heatmap.jpeg"))
    ggsave(file_path, plot = p, width = 15, height = 15, units = "in", dpi = 600)
}
```
